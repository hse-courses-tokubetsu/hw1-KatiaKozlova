{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашняя работа № 1\n",
    "## Общие правила\n",
    "- **Дедлайн: 27.09.2023 23:59**\n",
    "- Можно сдать до 28.09.2023 12:00 со штрафом в 50% от оценки, позже - только с официальным подтверждением от УО.\n",
    "- Оценивание: каждый пункт 1 балл, при невыполнении первого пункта - ноль за всю работу.\n",
    "\n",
    "**Важно!**\n",
    "Изменилась форма сдачи: теперь сдаем в github classroom (как на проге). Там возможно что-то догрузить после дедлайна, но это будет расцениваться как его несоблюдение.\n",
    "\n",
    "> [Ссылка](https://classroom.github.com/a/d3wAyVs3)\n",
    "\n",
    "## На оценку 6\n",
    "1. Выбрать любой корпус текстов и рассказать, октуда вы его взяли и почему именно его (ответ \"потому что он мне понравился\" тоже валиден):\n",
    "    - Он должен быть на русском и содержать порядка 1-2 тысяч записей (абзацев, текстов, предложений etc).\n",
    "    - Это может быть часть любого открытого корпуса, результат краулинга или даже генерации с помощью модели.\n",
    "    - Будет здорово, если он будет тематический (машины, лингвистика, литератруа etc), но не обязательно.\n",
    "2. Провести предобработку текста:\n",
    "    - лемматизация\n",
    "    - чистка от пунктуации и стоп-слов\n",
    "    - что-то еще, что вы считаете нужным\n",
    "3. Реализовать обратный индекс через частоты\n",
    "4. Реализовать обратный индекс через BM-25\n",
    "5. Реализовать поиск: на входе текст запроса и вариант индекса (частоты или bm-25), на выходе топ подходящих документов\n",
    "6. Описать в readme файле, как правильно запустить ваш код. \n",
    "\n",
    "## На оценку 8\n",
    "1. Реализовать частотный и BM-25 индекс руками через словари\n",
    "2. Реализовать их же через матрицы. Можно и нужно использовать scipy или numpy для матричных операций\n",
    "\n",
    "## На оценку 10\n",
    "1. Ваш код должен соотвествовать следующим критериям:\n",
    "    - Разделение на модули (разные файлы для разных больших блоков логики)\n",
    "    - Разделение на классы/функции\n",
    "    - Одна очевидная для пользователя точка входа: я могу запустить ваш код одной функцией, в которую подается текст\n",
    "    - Осмысленные имена переменных, функций, классов, модулей\n",
    "2. Подумайте, как можно формально сравнить два способа индексации с точки зрения качества поиска. Опишите, какой способо вы придумали, и используйте его для сравнения частоного и BM-25 индекса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2\n",
    "\n",
    "import string\n",
    "import math\n",
    "import zipfile\n",
    "\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я выбрала корпус шуток, взятый с [Kaggle](https://www.kaggle.com/datasets/konstantinalbul/russian-jokes/). В нем больше записей, чем нам нужно, поэтому из него я выбрала только те шутки, чей рейтинг больше или равен 5. \n",
    "Почему я выбрала именно его? Во-первых, он тематический и на приколе. Во-вторых, я устала от того, что мы с друзьями вечно вспоминаем какие-то анекдоты, но никто не может их рассказать, потому что помнит лишь самую суть. По-моему, было бы здорово создать поисковик для таких случаев!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('jokes.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('jokes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1375"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_jokes = list(set(df[df.rating >= 5].text.values.tolist()))\n",
    "len(good_jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(sent: str) -> List[str]:\n",
    "    '''\n",
    "    This function lemmatizes one string\n",
    "    :param sent: one raw string\n",
    "    :return: list of lemmatized words of the string\n",
    "    '''\n",
    "    lemmatized_string = []\n",
    "    for word in nltk.word_tokenize(sent, language=\"russian\"):\n",
    "        lemma = morph.parse(word)[0].normal_form.strip(string.punctuation + '«—»')\n",
    "        lemma = lemma.replace('ё', 'е')\n",
    "        if lemma and lemma not in russian_stopwords and lemma not in (string.punctuation + '«—»') and lemma != '...':\n",
    "            lemmatized_string.append(lemma)\n",
    "    return lemmatized_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_lemmatization(sentences: List[str]) -> List[List[str]]:\n",
    "    '''\n",
    "    This function lemmatizes sentences\n",
    "    :param sentences: list of raw strings\n",
    "    :return: list of senetences as a list of lemmatized words\n",
    "    '''\n",
    "    lemmatized_texts = []\n",
    "    for sentence in sentences:\n",
    "        lemmatized_text = lemmatization(sentence)\n",
    "        lemmatized_texts.append(lemmatized_text)\n",
    "    return lemmatized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManualFreq:\n",
    "    '''\n",
    "    This class realizes frequency ranking score for a corpus of texts.\n",
    "    :attr corpus_size_: int: number of documents in the corpus\n",
    "    :attr frequency_dict_: Dict[int, Dict[int, int]]: reversed frequency dictionary\n",
    "    :attr vocabulary_: Dict[str, int]: dictionary with all the terms in the corpus with their indexes in the reversed frequency dictionary\n",
    "    '''\n",
    "    def fit(self, corpus: List[List[str]]):\n",
    "        '''\n",
    "        This function calculates various reversed frequency dictionary to calculate frequency ranking score.\n",
    "        :param corpus: list of senetences as a list of lemmatized words\n",
    "        '''\n",
    "        frequency_dict, vocabulary = {}, {}\n",
    "        for i, doc in enumerate(corpus):\n",
    "            for word in doc:\n",
    "                if word not in vocabulary:\n",
    "                    vocabulary[word] = len(vocabulary)\n",
    "                num_word = vocabulary[word]\n",
    "                \n",
    "                if num_word not in frequency_dict:\n",
    "                    frequency_dict[num_word] = {}\n",
    "                if i not in frequency_dict[num_word]:\n",
    "                    frequency_dict[num_word][i] = 0\n",
    "                \n",
    "                frequency_dict[num_word][i] += 1\n",
    "        \n",
    "        self.corpus_size_ = len(corpus)\n",
    "        self.frequency_dict_ = frequency_dict\n",
    "        self.vocabulary_ = vocabulary\n",
    "\n",
    "    def search(self, query: List[str]) -> List[float]:\n",
    "        '''\n",
    "        This function makes a list of scores for each document in the corpus to cater the current search query.\n",
    "        :param query: search query\n",
    "        :return: frequency ranking scores for each document in the corpus\n",
    "        '''\n",
    "        freq = {}\n",
    "        for term in query:\n",
    "            if term in self.vocabulary_:\n",
    "                for doc, times in self.frequency_dict_[self.vocabulary_[term]].items():\n",
    "                    if doc in freq:\n",
    "                        freq[doc] += times\n",
    "                    else:\n",
    "                        freq[doc] = times\n",
    "                        \n",
    "        scores = [freq[i] if i in freq else 0 for i in range(self.corpus_size_)]\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25:\n",
    "    '''\n",
    "    This class realizes BM25 ranking score for a corpus of texts.\n",
    "    :attr tf_: List[Dict[str, int]]: term frequency per document\n",
    "    :attr df_: Dict[str, int]: document frequency per term\n",
    "    :attr idf_: Dict[str, float]: inverse document frequency per term\n",
    "    :attr doc_len_: List[int]: number of terms per document\n",
    "    :attr corpus_: List[List[str]]: the input corpus\n",
    "    :attr corpus_size_: int: number of documents in the corpus.\n",
    "    :attr avg_doc_len_: float: average number of terms for documents in the corpus.\n",
    "    '''\n",
    "    def __init__(self, k: float=1.5, b: float=0.75):\n",
    "        '''\n",
    "        This function intializes the magic parameters.\n",
    "        :param k1: first magic parameter \n",
    "        :param b: second magic parameter\n",
    "        '''\n",
    "        self.b = b\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, corpus: List[List[str]]):\n",
    "        '''\n",
    "        This function fits the various statistics to calculate BM25 ranking score.\n",
    "        :param corpus: list of senetences as a list of lemmatized words\n",
    "        '''\n",
    "        tf, df, idf, doc_len = [], {}, {}, []\n",
    "        corpus_size = 0\n",
    "        for document in corpus:\n",
    "            corpus_size += 1\n",
    "            doc_len.append(len(document))\n",
    "            frequencies = {}\n",
    "            for term in document:\n",
    "                frequencies[term] = frequencies.get(term, 0) + 1\n",
    "            tf.append(frequencies)\n",
    "            \n",
    "            for term in frequencies:\n",
    "                df[term] = df.get(term, 0) + 1\n",
    "                \n",
    "        for term, freq in df.items():\n",
    "            idf[term] = math.log(1 + (corpus_size - freq + 0.5) / (freq + 0.5))\n",
    "        \n",
    "        self.tf_ = tf\n",
    "        self.df_ = df\n",
    "        self.idf_ = idf\n",
    "        self.doc_len_ = doc_len\n",
    "        self.corpus_ = corpus\n",
    "        self.corpus_size_ = corpus_size\n",
    "        self.avg_doc_len_ = sum(doc_len) / corpus_size\n",
    "\n",
    "    def score(self, query: List[str], index: int) -> float:\n",
    "        '''\n",
    "        This function computes score for the current document to cater the current search query.\n",
    "        :param query: search query\n",
    "        :param index: index of the current document in the corpus\n",
    "        :return: BM25 ranking score for the current document\n",
    "        '''\n",
    "        score = 0.0\n",
    "        doc_len = self.doc_len_[index]\n",
    "        frequencies = self.tf_[index]\n",
    "        for term in query:\n",
    "            if term in frequencies:\n",
    "                freq = frequencies[term]\n",
    "                score += ((self.idf_[term] * freq * (self.k + 1)) / \n",
    "                          (freq + self.k * (1 - self.b + self.b * doc_len / self.avg_doc_len_)))\n",
    "                \n",
    "        return score\n",
    "\n",
    "    def search(self, query: List[str]) -> List[float]:\n",
    "        '''\n",
    "        This function makes a list of scores for each document in the corpus to cater the current search query.\n",
    "        :param query: search query\n",
    "        :return: BM25 ranking scores for each document in the corpus\n",
    "        '''\n",
    "        scores = [self.score(query, index) for index in range(self.corpus_size_)]\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_jokes(corpus: List[List[str]], current_query: List[str], n: int=10):\n",
    "    '''\n",
    "    This function prints top-n most high ranked jokes to cater current search query.\n",
    "    :param corpus: the input corpus\n",
    "    :param query: the input search query\n",
    "    :param n: the quantity of jokes (default top-10)\n",
    "    '''\n",
    "    ranker = input('Choose one ranker (BM25 / ManualBM25 / Freq / ManualFreq):\\n')\n",
    "    tokenized_corpus = sentences_lemmatization(corpus)\n",
    "    tokenized_query = lemmatization(current_query)\n",
    "    if ranker == 'ManualBM25':\n",
    "        bm25 = BM25()\n",
    "        bm25.fit(tokenized_corpus)\n",
    "        query_scores = bm25.search(tokenized_query)\n",
    "        top_n = [f'{str(i + 1)}.\\n{pair[1]}\\n' \n",
    "                 for i, pair in enumerate(sorted(zip(query_scores, corpus), key=lambda x: x[0], reverse=True)[:n])]\n",
    "        \n",
    "    elif ranker == 'BM25':\n",
    "        bm25 = BM25Okapi(tokenized_corpus)\n",
    "        top_n = [f'{str(i + 1)}.\\n{joke}\\n' \n",
    "                 for i, joke in enumerate(bm25.get_top_n(tokenized_query, corpus, n=n))]\n",
    "        \n",
    "    elif ranker == 'ManualFreq':\n",
    "        man_freq = ManualFreq()\n",
    "        man_freq.fit(tokenized_corpus)\n",
    "        query_scores = man_freq.search(tokenized_query)\n",
    "        top_n = [f'{str(i + 1)}.\\n{pair[1]}\\n' \n",
    "                 for i, pair in enumerate(sorted(zip(query_scores, corpus), key=lambda x: x[0], reverse=True)[:n])]\n",
    "        \n",
    "    elif ranker == 'Freq':\n",
    "        preprocessed_jokes = [' '.join(sentence) for sentence in sentences_lemmatization(corpus)]\n",
    "        cv = CountVectorizer()\n",
    "        freq_spm = cv.fit_transform(preprocessed_jokes)\n",
    "        sparce_matrix = freq_spm.toarray()\n",
    "        query_scores = np.zeros((len(corpus),))\n",
    "        list_of_terms = cv.get_feature_names()\n",
    "        for word in tokenized_query:\n",
    "            if word in list_of_terms:\n",
    "                idex = list_of_terms.index(word)\n",
    "                query_scores += sparce_matrix[:, idex]\n",
    "        top_n = [f'{str(i + 1)}.\\n{pair[1]}\\n' \n",
    "                 for i, pair in enumerate(sorted(zip(query_scores, corpus), key=lambda x: x[0], reverse=True)[:n])]\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Ranker must be BM25 / ManualBM25 / Freq / ManualFreq!\")\n",
    "        \n",
    "    print(''.join(top_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose one ranker (BM25 / ManualBM25 / Freq / ManualFreq):\n",
      "ManualBM25\n",
      "1.\n",
      "Вовочка приходит в класс с распухшей губой. Учительница:\n",
      "- Вовочка, что случилось?\n",
      "- Были с отцом на рыбалке, так оса на губу села.\n",
      "- И что - укусила?\n",
      "- Не, батя веслом убил!\n",
      "\n",
      "\n",
      "2.\n",
      "На уроке истории учительница спрашивает:\n",
      "- Почему США бомбят Ирак.\n",
      "Вовочка тянет руку:\n",
      "- Можно я! Я знаю.\n",
      "Учительница:\n",
      "- Ну скажи..\n",
      "Вовочка:\n",
      "- Потому что Моника сосала у Клинтона!!!.\n",
      "Учительница:\n",
      "- Вовочка вон из класса!.\n",
      "Ну а кто скажет почему Англия бомбит Ирак.\n",
      "Вовочка на ходу:\n",
      "- Я скажу! я честно знаю.\n",
      "Учительница:\n",
      "- Ну говори Вовочка...\n",
      "Вовочка:\n",
      "- А она ПОДГЛЯДЫВАЛА!!\n",
      "\n",
      "\n",
      "3.\n",
      "Урок биологии. Учительница:\n",
      "- Вовочка, расскажи всему классу, как размножаются дождевые черви?\n",
      "Вовочка:\n",
      "- Делением, Антонина Петровна.\n",
      "Учительница:\n",
      "- А поподробнее?\n",
      "Вовочка:\n",
      "- Лопатой.\n",
      "\n",
      "\n",
      "4.\n",
      "Отец воспитывает Вовочку:\n",
      "-Вместо того чтобы учиться, ты бегаешь по девчонкам!\n",
      "-Но папа...\n",
      "-Не перебивай, кто здесь отец, я или ты?\n",
      "-Оба батя, оба, - вздыхает Вовочка.\n",
      "\n",
      "\n",
      "5.\n",
      "Учительница, обращаясь к классу:\n",
      "- Дети, я просмотрела ваши сочинения на тему «Моя семья». Вовочка, почему ты написал «Отец у меня - дурак, мать тоже - дура. А я - самый умный в семье! »\n",
      "- Так родители сами говорят об этом. Отец - дурак, что женился. Мать – дура, что вышла замуж! А я жениться пока не собираюсь...\n",
      "\n",
      "6.\n",
      "Учительница:\n",
      "- Вовочка, назови каких-нибудь два местоимения.\n",
      "- Кто, я?\n",
      "- Молодец, Вовочка.\n",
      "\n",
      "\n",
      "7.\n",
      "Учительница на уроке дает задание:\n",
      "- Дети на завтра задаю вам сочинить стих!\n",
      "Hа следующий день... Вовочка выходит к доске:\n",
      "- Ну давай Вовочка!...\n",
      "Вовочка:\n",
      "- Стоит статУя\n",
      "В лучах заката\n",
      "С огромным хУем\n",
      "В руках лопата!\n",
      "Учительница:\n",
      "- Вовочка а можно как нибудь без Этого?!\n",
      "Вовочка с ходу:\n",
      "- Стоит статУя\n",
      "В лучах заката\n",
      "С обрубком хУя\n",
      "В руках лопата!\n",
      "Учительница:\n",
      "- Вовочка а можно СОВСЕМ без ЭТОГО?!!!!\n",
      "Вовочка: - Стоит статУя\n",
      "В лучах заката\n",
      "Совсем без хУя\n",
      "в руках лопата!\n",
      "Учительница (обреченно так):\n",
      "- Вовочка ну я же просила - без ЭТОГО....\n",
      "Вовочка:\n",
      "- Стоит лопата\n",
      "В лучах заката!\n",
      "CтатУя с хУем\n",
      "ушла куда-то...\n",
      "\n",
      "\n",
      "8.\n",
      "Учительница на уроке дает задание:\n",
      "- Дети на завтра задаю вам сочинить стих!\n",
      "Hа следующий день... Вовочка выходит к доске:\n",
      "- Ну давай Вовочка! ...\n",
      "Вовочка:\n",
      "- Стоит статУя\n",
      "В лучах заката\n",
      "С огромным хУем\n",
      "В руках лопата!\n",
      "Учительница:\n",
      "- Вовочка а можно как нибудь без Этого?!\n",
      "Вовочка с ходу:\n",
      "- Стоит статУя\n",
      "В лучах заката\n",
      "С обрубком х%я\n",
      "В руках лопата!\n",
      "Учительница:\n",
      "- Вовочка а можно СОВСЕМ без ЭТОГО? !!! !\n",
      "Вовочка: - Стоит статУя\n",
      "В лучах заката\n",
      "Совсем без х%я в руках лопата!\n",
      "Учительница (обреченно так):\n",
      "- Вовочка ну я же просила - без ЭТОГО... .\n",
      "Вовочка:\n",
      "- Стоит лопата\n",
      "В лучах заката!\n",
      "CтатУя с хУем ушла куда-то...\n",
      "\n",
      "9.\n",
      "Идет урок. Учительница просит детей перечислить слова на\n",
      "букву Х. Вовочка первый тянет руку. Учительница опасается,\n",
      "что он скажет что-нибудь неприличное. И спрашивает других\n",
      "детей. Те: хвост, холм...\n",
      "- Спасибо, дети. А теперь слова на букву П.\n",
      "Вовочка первый тянет руку. Учительница опять опасается,\n",
      "что он скажет что-нибудь неприличное. Дети: прачка, пони...\n",
      "- А теперь слова на букву К.\n",
      "Вовочка как всегда первый. Учительница, не найдя никаких\n",
      "плохих слов на К, спрашивает Вовочку.\n",
      "Вовочка: - Карлик, но вот с таким хуем.\n",
      "\n",
      "\n",
      "10.\n",
      "Дети заходят в класс и здороваются с учительницей.\n",
      "А Вовочка молча прошел и сел за парту.\n",
      "Учительница говорит:\n",
      "- Ты почему так некультурно себя ведешь? Вот выйди сейчас из\n",
      "класса и зайди так, как тебя учили, или как заходит домой твой отец.\n",
      "Вовочка выходит из класса. Через некоторое время врывается,\n",
      "открывая дверь ногой, и кричит:\n",
      "- Что, суки, не ждали?!\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_top_n_jokes(good_jokes, 'Вовочка рассказывает отцу про учительницу')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
